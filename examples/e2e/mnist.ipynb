{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da3bb75c-8160-442c-aed0-05849b37a9fd",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "#### Loading MNIST code taken from https://github.com/oreilly-japan/deep-learning-from-scratch/blob/master/dataset/mnist.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc8d38b4-f3b6-46dd-8366-a9e99449c986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os.path\n",
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "url_base = 'http://yann.lecun.com/exdb/mnist/'\n",
    "key_file = {\n",
    "    'train_img':'train-images-idx3-ubyte.gz',\n",
    "    'train_label':'train-labels-idx1-ubyte.gz',\n",
    "    'test_img':'t10k-images-idx3-ubyte.gz',\n",
    "    'test_label':'t10k-labels-idx1-ubyte.gz'\n",
    "}\n",
    "\n",
    "dataset_dir = \".\"\n",
    "save_file = dataset_dir + \"/mnist.pkl\"\n",
    "\n",
    "train_num = 60000\n",
    "test_num = 10000\n",
    "img_dim = (1, 28, 28)\n",
    "img_size = 784\n",
    "\n",
    "\n",
    "def _download(file_name):\n",
    "    file_path = dataset_dir + \"/\" + file_name\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        return\n",
    "\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0\"}\n",
    "    request = urllib.request.Request(url_base+file_name, headers=headers)\n",
    "    response = urllib.request.urlopen(request).read()\n",
    "    with open(file_path, mode='wb') as f:\n",
    "        f.write(response)\n",
    "\n",
    "def download_mnist():\n",
    "    for v in key_file.values():\n",
    "       _download(v)\n",
    "\n",
    "def _load_label(file_name):\n",
    "    file_path = dataset_dir + \"/\" + file_name\n",
    "\n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "            labels = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "\n",
    "    return labels\n",
    "\n",
    "def _load_img(file_name):\n",
    "    file_path = dataset_dir + \"/\" + file_name\n",
    "\n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    data = data.reshape(-1, img_size)\n",
    "\n",
    "    return data\n",
    "\n",
    "def _convert_numpy():\n",
    "    dataset = {}\n",
    "    dataset['train_img'] =  _load_img(key_file['train_img'])\n",
    "    dataset['train_label'] = _load_label(key_file['train_label'])\n",
    "    dataset['test_img'] = _load_img(key_file['test_img'])\n",
    "    dataset['test_label'] = _load_label(key_file['test_label'])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def init_mnist():\n",
    "    download_mnist()\n",
    "    dataset = _convert_numpy()\n",
    "    with open(save_file, 'wb') as f:\n",
    "        pickle.dump(dataset, f, -1)\n",
    "\n",
    "def _change_one_hot_label(X):\n",
    "    T = np.zeros((X.size, 10))\n",
    "    for idx, row in enumerate(T):\n",
    "        row[X[idx]] = 1\n",
    "\n",
    "    return T\n",
    "\n",
    "\n",
    "def load_mnist(normalize=True, flatten=True, one_hot_label=False):\n",
    "    \"\"\"MNISTデータセットの読み込み\n",
    "    Parameters\n",
    "    ----------\n",
    "    normalize : 画像のピクセル値を0.0~1.0に正規化する\n",
    "    one_hot_label :\n",
    "        one_hot_labelがTrueの場合、ラベルはone-hot配列として返す\n",
    "        one-hot配列とは、たとえば[0,0,1,0,0,0,0,0,0,0]のような配列\n",
    "    flatten : 画像を一次元配列に平にするかどうか\n",
    "    Returns\n",
    "    -------\n",
    "    (訓練画像, 訓練ラベル), (テスト画像, テストラベル)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(save_file):\n",
    "        init_mnist()\n",
    "\n",
    "    with open(save_file, 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "\n",
    "    if normalize:\n",
    "        for key in ('train_img', 'test_img'):\n",
    "            dataset[key] = dataset[key].astype(np.float32)\n",
    "            dataset[key] /= 255.0\n",
    "\n",
    "    if one_hot_label:\n",
    "        dataset['train_label'] = _change_one_hot_label(dataset['train_label'])\n",
    "        dataset['test_label'] = _change_one_hot_label(dataset['test_label'])\n",
    "\n",
    "    if not flatten:\n",
    "         for key in ('train_img', 'test_img'):\n",
    "            dataset[key] = dataset[key].reshape(-1, 1, 28, 28)\n",
    "\n",
    "    return dataset['train_img'], dataset['train_label'], dataset['test_img'], dataset['test_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "142c0538-e09c-47e5-8599-3c50a1ebd45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fa486e0-7bd2-4341-9be0-c4f194c18079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c63d77d-b68e-4254-a1e6-9931d4af1ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), (10000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test .shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d523d06b-e45c-4c45-9750-249f922f3c47",
   "metadata": {},
   "source": [
    "## SimpleNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7328747-df28-4f00-a2e6-7457e57a0d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -e ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d119b24a-3665-45cd-92ae-5060db1b024d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0          loss=0.1892     reg_loss=0.3891    Train_acc=0.8908     Val_acc=0.8895     lr=0.0010    \n",
      "epoch=1          loss=0.3945     reg_loss=0.5811    Train_acc=0.9341     Val_acc=0.9338     lr=0.0009    \n",
      "epoch=2          loss=0.1906     reg_loss=0.3694    Train_acc=0.9497     Val_acc=0.9493     lr=0.0009    \n",
      "epoch=3          loss=0.3094     reg_loss=0.4855    Train_acc=0.9534     Val_acc=0.9520     lr=0.0008    \n",
      "epoch=4          loss=0.3491     reg_loss=0.5193    Train_acc=0.9581     Val_acc=0.9558     lr=0.0008    \n",
      "epoch=5          loss=0.1053     reg_loss=0.2714    Train_acc=0.9635     Val_acc=0.9607     lr=0.0008    \n",
      "epoch=6          loss=0.1641     reg_loss=0.3262    Train_acc=0.9632     Val_acc=0.9642     lr=0.0008    \n",
      "epoch=7          loss=0.0774     reg_loss=0.2392    Train_acc=0.9640     Val_acc=0.9625     lr=0.0007    \n",
      "epoch=8          loss=0.1280     reg_loss=0.2846    Train_acc=0.9694     Val_acc=0.9673     lr=0.0007    \n",
      "epoch=9          loss=0.2050     reg_loss=0.3613    Train_acc=0.9671     Val_acc=0.9654     lr=0.0007    \n",
      "epoch=10         loss=0.1761     reg_loss=0.3303    Train_acc=0.9652     Val_acc=0.9631     lr=0.0007    \n",
      "epoch=11         loss=0.0901     reg_loss=0.2420    Train_acc=0.9692     Val_acc=0.9651     lr=0.0006    \n",
      "epoch=12         loss=0.0917     reg_loss=0.2421    Train_acc=0.9687     Val_acc=0.9641     lr=0.0006    \n",
      "epoch=13         loss=0.0412     reg_loss=0.1908    Train_acc=0.9720     Val_acc=0.9670     lr=0.0006    \n",
      "epoch=14         loss=0.0223     reg_loss=0.1681    Train_acc=0.9696     Val_acc=0.9663     lr=0.0006    \n",
      "Train Accuracy: 0.96955\n"
     ]
    }
   ],
   "source": [
    "from simplenn import Network\n",
    "from simplenn.layer import Dense\n",
    "from simplenn.activation import ReLu\n",
    "from simplenn.activation import SoftMaxLoss\n",
    "from simplenn.layer.dropout import Dropout\n",
    "from simplenn.metrics.loss import CategoricalCrossEntropy\n",
    "from simplenn.metrics import Accuracy\n",
    "from simplenn.optimizers import Adam\n",
    "\n",
    "class Model(Network):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.l1 = Dense(img_size, 64, W_l1=5e-4, b_l1=5e-4)\n",
    "        self.dropout1 = Dropout(rate=0.2)\n",
    "        self.activation1 = ReLu()\n",
    "        self.l2 = Dense(64, 64)\n",
    "        self.dropout2 = Dropout(rate=0.2)\n",
    "        self.activation2 = ReLu()\n",
    "        self.l3 = Dense(64, 10)\n",
    "        self.output = SoftMaxLoss(loss=CategoricalCrossEntropy())\n",
    "\n",
    "    def forward(self, x, targets):\n",
    "        # forward pass\n",
    "        x = self.l1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.l3(x)\n",
    "        return self.output(x, targets)\n",
    "\n",
    "\n",
    "optimizer = Adam(lr=0.001, decay=5e-5, b1=0.9, b2=0.999)\n",
    "acc = Accuracy()\n",
    "model = Model(optimizer=optimizer)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=15, batch_size=64, metrics=[acc], X_val=X_test, y_val=y_test)\n",
    "\n",
    "yprob_train = model.predict(X_train)\n",
    "train_acc = acc(yprob_train, y_train)\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1de5fe24-fcdf-410a-a216-f5e202840dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9663\n"
     ]
    }
   ],
   "source": [
    "yprob_test= model.predict(X_test)\n",
    "test_acc = acc(yprob_test, y_test)\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7da4d4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('mnist_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12870f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "beb691a3d7e8acd160e47ddb9ac66784b63a78ab5ee1096e93f35d22fafb9a3f"
  },
  "kernelspec": {
   "display_name": "simple",
   "language": "python",
   "name": "simple"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
